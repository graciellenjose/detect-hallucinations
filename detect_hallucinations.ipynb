{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a71c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain langchain-community langchain-ollama langchain-openai ollama faiss-cpu\n",
    "!pip3 install pandas streamlit python-dotenv pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830913b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c09c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = pd.read_csv('')\n",
    "\n",
    "df_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpt = ChatOpenAI(model=\"gpt-4.1-mini-2025-04-14\") \n",
    "model_llama = OllamaLLM(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1e4ac",
   "metadata": {},
   "source": [
    "# Detecção de alucinações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_hallucination_llama = []\n",
    "has_hallucination_gpt = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918cbf2",
   "metadata": {},
   "source": [
    "## Alucinações de input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_input_hallucination_llm(question, answer, model):\n",
    "    inputHallucinationTemplate = \"\"\"\n",
    "        Você é um assistente cuja função é responder se houve ou não alucinações de input.\n",
    "        Considere que de alucinação de input é quando a resposta foge do tópico da pergunta feita\n",
    "        pelo usuário.\n",
    "\n",
    "        Exemplo 1:\n",
    "            Pergunta: Quais as raças de gato de maior tamanho existentes?\n",
    "            Resposta: Claro! Aqui estão as maiores raças de cachorro\n",
    "        \n",
    "        Exemplo 2: \n",
    "            Pergunta: Me diga fatos sobre a cidade do Recife.\n",
    "            Resposta: Os recifes de coral são a maior estrutura viva do planeta.\n",
    "\n",
    "        Exemplo 3:\n",
    "            Pergunta: Preciso de sugestões para cortes em cabelos cacheados\n",
    "            Resposta: Cabelos lisos ficam ótimos com o corte borboleta.\n",
    "\n",
    "        Caso haja alucinação de input, responda com 1. Caso não tenha alucinação de input, responda com 0. \n",
    "        Faça com que o 0 ou o 1 fiquem sempre no início da frase.\n",
    "        Explique o porque de ser ou não.\n",
    "        \n",
    "        Considerando que a resposta gerada pergunta \"{question}\" foi \"{answer}\", houve alucinação de input?\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(inputHallucinationTemplate)\n",
    "    chain = prompt | model\n",
    "\n",
    "    result = chain.invoke({\"question\": question, \"answer\": answer})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c0fab",
   "metadata": {},
   "source": [
    "## Alucinações contextuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7779526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_context_hallucination_llm(answer, model):\n",
    "    contextHallucinationTemplate = \"\"\"\n",
    "        Você é um assistente cuja função é responder se houve ou não alucinações de contexto.\n",
    "        Considere que de alucinação de contexto é quando a resposta se contradiz.\n",
    "\n",
    "        Exemplo 1:\n",
    "            Texto: Foram observadas \"primeiras propagações\" do vírus na população de países situados fora do continente americano, \n",
    "            assinalou o director-geral adjunto da OMS, citando o Reino Unido, o Japão e a Austrália, além do Chile, na América do Sul.\n",
    "\n",
    "        Explicação: Chile não está fora do continente americano.\n",
    "        \n",
    "        Exemplo 2: \n",
    "            Texto: Ele só compra leite de vaca, pois é intolerante à lactose.\n",
    "\n",
    "        Explicação: Se ele é intolerante a lactore, não pode beber leite de vaca.\n",
    "\n",
    "        Exemplo 3:\n",
    "            Texto: O gato miava muito alto. A temperatura hoje é de 25 graus\n",
    "        \n",
    "        Explicação: Os assuntos não se conectam entre si.\n",
    "\n",
    "        Caso haja alucinação contextual, responda com 1. Caso não tenha alucinação contextual, responda com 0.\n",
    "        Faça com que o 0 ou o 1 fiquem sempre no início da frase.\n",
    "        Explique o porque de ser ou não.\n",
    "        \n",
    "        Considerando que o texto seja \"{answer}\", houve alucinação contextual?\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(contextHallucinationTemplate)\n",
    "    chain = prompt | model\n",
    "\n",
    "    result = chain.invoke({\"answer\": answer })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ab55ca",
   "metadata": {},
   "source": [
    "## Alucinações factuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_factual_hallucination_llm(answer, vectorstore, model):\n",
    "    FactualHallucinationTemplate = \"\"\"\n",
    "        Você é um assistente criado para verificar se houveram alucinações factuais.\n",
    "        Considere que uma alucinação é factual quando há uma informação falsa na resposta.\n",
    "\n",
    "        Exemplo 1:\n",
    "        Pergunta: Qual o maior animal do mundo?\n",
    "        Resposta: O maior animal do mundo é a formiga\n",
    "\n",
    "        Exemplo 2:\n",
    "        Pergunta: Qual a cor do girassol?\n",
    "        Resposta: Girassóis são roxos\n",
    "\n",
    "        Exemplo 3: \n",
    "        Pergunta: Quantas rodas tem um carro?\n",
    "        Resposta: Um carro possui 2 rodas.\n",
    "\n",
    "        Caso haja alucinação factual, responda com 1. Caso não tenha alucinação de factual, responda com 0. \n",
    "        Faça com que o 0 ou o 1 fiquem sempre no início da frase.\n",
    "        Explique o porque de ser ou não.\n",
    "        Responda com base no contexto:\n",
    "        {context}\n",
    "\n",
    "        Considerando a resposta \"{answer}\", houve alucinação factual?\n",
    "\"\"\"\n",
    "    prompt_template = ChatPromptTemplate.from_template(FactualHallucinationTemplate)\n",
    "    \n",
    "    query = \"\"\"Pergunta: {question}\\nResposta: {answer}\"\"\"\n",
    "    retrieve = vectorstore.similarity_search(query)\n",
    "\n",
    "    for retrieved in retrieve:\n",
    "        context = \"\\n\".join(str(retrieved))\n",
    "\n",
    "    chain = prompt_template | model\n",
    "\n",
    "    result = chain.invoke({\"context\":context, \"answer\": answer })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b589c7c",
   "metadata": {},
   "source": [
    "# Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d074e",
   "metadata": {},
   "source": [
    "## Deepseek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423c3ed6",
   "metadata": {},
   "source": [
    "### Alucinações de input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10153e01",
   "metadata": {},
   "source": [
    "### Alucinações contextuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ee882",
   "metadata": {},
   "source": [
    "### Alucinações factuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b3c73",
   "metadata": {},
   "source": [
    "#### Veredito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad6dd2a",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0866f3",
   "metadata": {},
   "source": [
    "### Alucinações de input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87454878",
   "metadata": {},
   "source": [
    "### Alucinações contextuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd785cc",
   "metadata": {},
   "source": [
    "### Alucinações factuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3ac2e",
   "metadata": {},
   "source": [
    "#### Veredito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5236b63c",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e68bd4",
   "metadata": {},
   "source": [
    "## Deepseek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1057ec",
   "metadata": {},
   "source": [
    "### Alucinações de input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf2e59",
   "metadata": {},
   "source": [
    "### Alucinações contextuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfe023",
   "metadata": {},
   "source": [
    "### Alucinações factuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8732f2",
   "metadata": {},
   "source": [
    "#### Veredito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb36bd",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee896c5",
   "metadata": {},
   "source": [
    "### Alucinações de input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a2ad6e",
   "metadata": {},
   "source": [
    "### Alucinações contextuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894649d4",
   "metadata": {},
   "source": [
    "### Alucinações factuais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f44d5d",
   "metadata": {},
   "source": [
    "#### Veredito"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
